{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torchvision을 사용해 데이터 불러오기\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "#train data와 test data를 다운로드\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# 이미지를 보여주기 위한 함수\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize 다시 [0, 1]로 바꿈\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# 학습용 이미지를 무작위로 가져오기\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# 이미지 보여주기\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "#\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #convolution layer, pooling layer, fully connected layer 정의\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) # input channels, output channels, kernel(fliter) size, 1 * 28 * 28 ->  6 * 24 * 24\n",
    "        #(28 - 5) + 1 이므로 24가 됨.\n",
    "        self.pool = nn.MaxPool2d(2)  # kernel size, stride = 1, padding = 0 (default) stride를 2로하면 4씩 작아지니까\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) # 6 * 12 * 12 -> 16 * 8 * 8\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 256) # input features, output features\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) # 6 * 24 * 24 -> 6 * 12 * 12\n",
    "        x = self.pool(F.relu(self.conv2(x))) # 16 * 8 * 8 -> 16 * 4 * 4\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#손실함수는 교차엔트로피, optimizer는 확률적 경사하강법으로 설정.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 2.293\n",
      "[1,  1000] loss: 2.022\n",
      "[1,  1500] loss: 0.776\n",
      "[1,  2000] loss: 0.507\n",
      "[1,  2500] loss: 0.388\n",
      "[1,  3000] loss: 0.281\n",
      "[1,  3500] loss: 0.278\n",
      "[1,  4000] loss: 0.236\n",
      "[1,  4500] loss: 0.203\n",
      "[1,  5000] loss: 0.186\n",
      "[2,   500] loss: 0.169\n",
      "[2,  1000] loss: 0.156\n",
      "[2,  1500] loss: 0.166\n",
      "[2,  2000] loss: 0.141\n",
      "[2,  2500] loss: 0.117\n",
      "[2,  3000] loss: 0.131\n",
      "[2,  3500] loss: 0.141\n",
      "[2,  4000] loss: 0.124\n",
      "[2,  4500] loss: 0.106\n",
      "[2,  5000] loss: 0.122\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # 데이터셋을 수차례 반복합니다. training 부분\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 입력을 받은 후\n",
    "        inputs, labels = data\n",
    "\n",
    "        # 변화도(Gradient) 매개변수를 0으로 만든 후\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 순전파 + 역전파 + 최적화\n",
    "        outputs = net(inputs) #순전파\n",
    "        loss = criterion(outputs, labels) #CEE로 loss를 구하고\n",
    "        loss.backward() #역전파\n",
    "        optimizer.step() #경사하강법을 이용해 최적화\n",
    "\n",
    "        # 통계 출력\n",
    "        running_loss += loss.item()\n",
    "        if i % 500 == 499:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 500))\n",
    "            running_loss = 0.0\n",
    "\n",
    "        if i == 5000:\n",
    "            break\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    7    2    1    0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#정답값과 이미지 출력\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(''.join('%5d' % labels[j] for j in range(4)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    7    2    1    0\n"
     ]
    }
   ],
   "source": [
    "#output은 10개의 class를 각각 예측해서 값을 갖고 있는데 그 중 max값을 저장\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print(''.join('%5d' % predicted[j] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96 %\n"
     ]
    }
   ],
   "source": [
    "#전체 dataset을 통해 정확도를 check\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport random\\n\\nr = random.randint(0, len(testset) -1)\\nX_single_data = Variable(testset.test_data[r:r + 1].view(-1,28 * 28).float())\\nY_single_data = Variable(testset.test_labels[r:r + 1])\\n\\nsingle_prediction = Net(X_single_data)\\n\\nprint(\"Label : \", Y_single_data.data)\\nprint(\"Prediction : \", torch.max(single_prediction.data, 1)[1])\\n\\nplt.imshow(X_single_data.data.view(28,28).numpy(), cmap=\\'gray\\')\\nplt.show()\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import random\n",
    "\n",
    "r = random.randint(0, len(testset) -1)\n",
    "X_single_data = Variable(testset.test_data[r:r + 1].view(-1,28 * 28).float())\n",
    "Y_single_data = Variable(testset.test_labels[r:r + 1])\n",
    "\n",
    "single_prediction = Net(X_single_data)\n",
    "\n",
    "print(\"Label : \", Y_single_data.data)\n",
    "print(\"Prediction : \", torch.max(single_prediction.data, 1)[1])\n",
    "\n",
    "plt.imshow(X_single_data.data.view(28,28).numpy(), cmap='gray')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n튜토리얼 과정\\n1. training, test 데이터셋을 불러오고 정규화\\n2. CNN모델 정의\\n3. loss와 optimizer 정의(손실함수와 경사하강법)\\n4. training data로 신경망 학습\\n5. test data로 검사(정확도 검사)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "튜토리얼 과정\n",
    "1. training, test 데이터셋을 불러오고 정규화\n",
    "2. CNN모델 정의\n",
    "3. loss와 optimizer 정의(손실함수와 경사하강법)\n",
    "4. training data로 신경망 학습\n",
    "5. test data로 검사(정확도 검사)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
